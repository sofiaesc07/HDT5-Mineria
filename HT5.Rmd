---
title: "HT5 - Naive Bayes"
author: "Stefan Quintana, Sofía Escobar, Wilfredo Gallegos"
date: "3/17/2023"
output: html_document
---

```{r, echo=FALSE}
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(ggplot2)
library(tidyr)
library(e1071)
library(caret)


datos <- read.csv("train.csv")
datos <- datos %>% mutate_at(c('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities'
                               , 'LotConfig', 'LandSlope', 'Condition2', 'RoofMatl', 'Exterior2nd', 'Electrical'),as.factor)
```


##Pregunta 1. Particion de los datos en dos conjuntos

Como los datos están balanceados se hizo una partición aleatoria utilizando el 70% de los datos para entrenamiento y el 30% de los datos para prueba.

```{r, echo = FALSE}
porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training1<-datos[corte,]
test1<-datos[-corte,]

datos2 <- dplyr::select_if(datos, is.numeric)
datos2 <- na.omit(datos2)
datosc <- scale(datos2)
corte <- sample(nrow(datosc),nrow(datosc)*porcentaje)
training<-datosc[corte,]
test<-datosc[-corte,]
test1$clasification <- ifelse(test1$SalePrice > 214000, "Caras", ifelse(test1$SalePrice>163000, "Intemedia", "Economicas"))

```

  
##Pregunta 2 y 3. Hacer un modelo de Naive Bayes y de clasficación
```{r}
training1$clasification <- ifelse(training1$SalePrice > 214000, "Caras", ifelse(training1$SalePrice>163000, "Intemedia", "Economicas"))
table(training1$clasification)
modelo1<-naiveBayes(training1$clasification~., data=training1)
modelo1
```

##Pregunta 4 y 7. Eficiencia del algoritmo y matriz de confusión
```{r}

predBayes<-predict(modelo1, test1)
prediction1 <- predict(modelo1, test1)
prediction1<-as.factor(prediction1)
cm<-caret::confusionMatrix(prediction1,as.factor(test1$clasification))
cm
```

##Pregunta 5. Analisis de resultados del modelo de clasificación

Con esto puede observarse que las probabilidades a priori obtenidas son: caras 0.2468168%, economicas 0.5073457% e intermedias 0.2458374%. Es decir, la mayoría de casas se encuentra en un rango de precio de venta económico, seguido por las casas con un precio de venta caras y por último se encuentran aquellas con un precio de venta intermedio.

##Pregunta 6. Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las hojas pasadas. ¿Cuál funcionó mejor?

##Pregunta 7. Analisis de la matriz de confusión

Dentro de la matriz de confusión realizada con la predicción y el conjunto de prueba, se observa que la precisión del modelo fue del 78.36% lo cual indica que es bastante acertado. El modelo presenta una exactitud balanceada arriba de 80% para todas las casas lo cual infdica que es aceptable para la clasificación, de igual forma sucede con la sensibilidad y especificidad, estas indican que el modelo es acertado debido a sus porcentajes. 

##Pregunta 8. Analice el modelo. ¿Cree que pueda estar sobre ajustado?

Debido al porcentaje de exactitud balanceado se podria llegar a pensar que si ya que es bastante alto, esto puede comprobarse por medio del un modelo de validación cruzada tal y como se observa a continuación. 

##Pregunta 9. Modelo de validación cruzada

```{r}
ct<-trainControl(method = "cv",number=10,verboseIter=T)
modeloCaret<-train(clasification~.,data=training1,method="nb",trControl = ct)
prediccionCaret<-predict(modeloCaret,newdata = test1)
caret::confusionMatrix(prediccionCaret,test1$SalePrice)
```

##Pregunta 10. Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?